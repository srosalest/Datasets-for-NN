{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Conv1D\n",
    "from keras.layers import MaxPooling2D, MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_final_labels = np.zeros((train_labels.size, train_labels.max()+1))\n",
    "train_final_labels[np.arange(train_labels.size),train_labels] = 1\n",
    "\n",
    "test_final_labels = np.zeros((test_labels.size, test_labels.max()+1))\n",
    "test_final_labels[np.arange(test_labels.size),test_labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape (28,28,1)\n",
    "final_train_images = []\n",
    "for index in range(0, len(train_images)):\n",
    "    final_train_images.append(train_images[index].reshape((28,28,1)))\n",
    "final_train_images = np.array(final_train_images)    \n",
    "\n",
    "test_final_images = []\n",
    "for index in range(0, len(test_images)):\n",
    "    test_final_images.append(test_images[index].reshape((28,28,1)))\n",
    "test_final_images = np.array(test_final_images)    \n",
    "\n",
    "\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(test_final_images, test_final_labels, test_size = 0.1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 3)         78        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 9)           684       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 9)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               18560     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 29,988\n",
      "Trainable params: 29,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(3,5,activation='relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(9,5,activation='relu',input_shape = (12,12,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 9000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.7270 - accuracy: 0.7251 - val_loss: 0.5020 - val_accuracy: 0.8152\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.5087 - accuracy: 0.8120 - val_loss: 0.4267 - val_accuracy: 0.8438\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.4620 - accuracy: 0.8298 - val_loss: 0.3980 - val_accuracy: 0.8538\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.4348 - accuracy: 0.8389 - val_loss: 0.3900 - val_accuracy: 0.8588\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.4096 - accuracy: 0.8488 - val_loss: 0.3747 - val_accuracy: 0.8607\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3962 - accuracy: 0.8530 - val_loss: 0.3643 - val_accuracy: 0.8616\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.3841 - accuracy: 0.8572 - val_loss: 0.3484 - val_accuracy: 0.8673\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.3747 - accuracy: 0.8609 - val_loss: 0.3469 - val_accuracy: 0.8722\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3652 - accuracy: 0.8640 - val_loss: 0.3396 - val_accuracy: 0.8739\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3597 - accuracy: 0.8661 - val_loss: 0.3370 - val_accuracy: 0.8738\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.3521 - accuracy: 0.8683 - val_loss: 0.3301 - val_accuracy: 0.8720\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3452 - accuracy: 0.8711 - val_loss: 0.3212 - val_accuracy: 0.8818\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.3436 - accuracy: 0.8724 - val_loss: 0.3245 - val_accuracy: 0.8813\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3367 - accuracy: 0.8746 - val_loss: 0.3178 - val_accuracy: 0.8827\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3317 - accuracy: 0.8758 - val_loss: 0.3122 - val_accuracy: 0.8834\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3312 - accuracy: 0.8766 - val_loss: 0.3153 - val_accuracy: 0.8824\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.3299 - accuracy: 0.8761 - val_loss: 0.3125 - val_accuracy: 0.8843\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3275 - accuracy: 0.8774 - val_loss: 0.3068 - val_accuracy: 0.8853\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3207 - accuracy: 0.8798 - val_loss: 0.3046 - val_accuracy: 0.8836\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.3207 - accuracy: 0.8803 - val_loss: 0.3166 - val_accuracy: 0.8836\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.3185 - accuracy: 0.8820 - val_loss: 0.3018 - val_accuracy: 0.8886\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.3136 - accuracy: 0.8820 - val_loss: 0.3166 - val_accuracy: 0.8823\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3092 - accuracy: 0.8842 - val_loss: 0.3003 - val_accuracy: 0.8904\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.3110 - accuracy: 0.8837 - val_loss: 0.3031 - val_accuracy: 0.8897\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3091 - accuracy: 0.8837 - val_loss: 0.2977 - val_accuracy: 0.8920\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3058 - accuracy: 0.8834 - val_loss: 0.3016 - val_accuracy: 0.8898\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3051 - accuracy: 0.8847 - val_loss: 0.3070 - val_accuracy: 0.8870\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.3030 - accuracy: 0.8860 - val_loss: 0.3056 - val_accuracy: 0.8860\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.3016 - accuracy: 0.8879 - val_loss: 0.3148 - val_accuracy: 0.8851\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.3001 - accuracy: 0.8866 - val_loss: 0.3038 - val_accuracy: 0.8896\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(final_train_images, train_final_labels,validation_data=(X_test, Y_test),\n",
    "                       epochs=epochs, batch_size=batch_size, verbose=1,\n",
    "                       callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30381203916337757 / Test accuracy: 0.8895555734634399\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30874385857582093 / Test accuracy: 0.890999972820282\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_fashion_adam_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
